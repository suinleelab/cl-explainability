{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0a597a8-35f2-4b32-ac93-68cd68aeeb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fa638cc-36e0-45ab-aa57-528d82f37768",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../scripts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b7a54c7-7a3b-459a-93cd-471dbf43dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants\n",
    "import torch\n",
    "from experiment_utils import (\n",
    "    load_data,\n",
    "    load_encoder,\n",
    ")\n",
    "from torch.utils.data import DataLoader, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c466ebbf-2f1f-4d79-8df0-c8699712af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cl_explain.explanations.contrastive_weighted_score import ContrastiveWeightedScore\n",
    "from cl_explain.explanations.corpus_similarity import CorpusSimilarity\n",
    "from cl_explain.explanations.contrastive_corpus_similarity import (\n",
    "    ContrastiveCorpusSimilarity,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48952948-7f50-40c1-87c3-748860afc489",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset, _, _ = load_data(\"imagenet\", \"val\", 32)\n",
    "val_labels = [sample[0].split(\"/\")[-2] for sample in val_dataset.samples]\n",
    "unique_labels = constants.IMAGENETTE_SYNSETS\n",
    "target = unique_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b25cd71a-b7be-4225-81dd-1ca65e076007",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_target_idx = (\n",
    "    torch.Tensor([label == target for label in val_labels])\n",
    "    .nonzero()\n",
    "    .flatten()\n",
    ")\n",
    "explicand_idx = val_target_idx[:25]\n",
    "corpus_idx = val_target_idx[25:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fead4b4-a7ae-4875-90a7-24b7f641409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "foil_idx = (\n",
    "    torch.Tensor(\n",
    "        [label != target and label in unique_labels for label in val_labels]\n",
    "    )\n",
    "    .nonzero()\n",
    "    .flatten()\n",
    ")\n",
    "foil_idx = foil_idx[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9016300-8251-4459-b996-a235c44aaa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "explicand_dataloader = DataLoader(\n",
    "    Subset(val_dataset, indices=explicand_idx),\n",
    "    batch_size=10,\n",
    "    shuffle=False,\n",
    ")\n",
    "corpus_dataloader = DataLoader(\n",
    "    Subset(val_dataset, indices=corpus_idx),\n",
    "    batch_size=10,\n",
    "    shuffle=False,\n",
    ")\n",
    "foil_dataloader = DataLoader(\n",
    "    Subset(val_dataset, indices=foil_idx),\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6d45610-f83a-4578-9272-863727f0fb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 7\n",
    "encoder = load_encoder(\"simclr_x1\")\n",
    "encoder.eval()\n",
    "encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5462b29c-3dca-4c29-9dc9-27665203d1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor([0.6939, 0.7007, 0.7347, 0.7576, 0.7563, 0.6887, 0.7761, 0.7717, 0.7657,\n",
      "        0.7613, 0.7140, 0.7742, 0.7496, 0.7881, 0.7606, 0.7860, 0.7703, 0.7824,\n",
      "        0.8042, 0.7562, 0.7138, 0.7650, 0.7633, 0.8058, 0.7943])\n"
     ]
    }
   ],
   "source": [
    "contrastive_weighted_score = ContrastiveWeightedScore(\n",
    "    encoder=encoder,\n",
    "    foil_dataloader=foil_dataloader,\n",
    "    normalize=True,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "fast_outs = []\n",
    "slow_outs = []\n",
    "for explicand, _ in explicand_dataloader:\n",
    "    explicand = explicand.to(device)\n",
    "    contrastive_weighted_score.generate_weight(explicand.detach().clone())\n",
    "    fast_out = contrastive_weighted_score.forward(explicand, implementation=\"mean\").detach().cpu()\n",
    "    slow_out = contrastive_weighted_score.forward(explicand, implementation=\"pairwise\").detach().cpu()\n",
    "    fast_outs.append(fast_out)\n",
    "    slow_outs.append(slow_out)\n",
    "fast_outs = torch.cat(fast_outs)\n",
    "slow_outs = torch.cat(slow_outs)\n",
    "print(torch.all(torch.isclose(fast_outs, slow_outs)))\n",
    "print(fast_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45d5aa50-9fc7-40ac-bb7b-b9f4f63d10be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor([ 53.5182, 153.3758, 183.1795, 151.6195, 166.7433, 131.0765, 224.8011,\n",
      "        377.9021, 168.5114, 372.6056, 175.8909, 275.7900, 208.8300, 320.5536,\n",
      "        190.5505, 266.5364, 204.7652, 201.4692, 434.9282, 151.1830, 108.3063,\n",
      "        174.5839, 174.9215, 243.8135, 498.4396])\n"
     ]
    }
   ],
   "source": [
    "contrastive_weighted_score = ContrastiveWeightedScore(\n",
    "    encoder=encoder,\n",
    "    foil_dataloader=foil_dataloader,\n",
    "    normalize=False,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "fast_outs = []\n",
    "slow_outs = []\n",
    "for explicand, _ in explicand_dataloader:\n",
    "    explicand = explicand.to(device)\n",
    "    contrastive_weighted_score.generate_weight(explicand.detach().clone())\n",
    "    fast_out = contrastive_weighted_score.forward(explicand, implementation=\"mean\").detach().cpu()\n",
    "    slow_out = contrastive_weighted_score.forward(explicand, implementation=\"pairwise\").detach().cpu()\n",
    "    fast_outs.append(fast_out)\n",
    "    slow_outs.append(slow_out)\n",
    "fast_outs = torch.cat(fast_outs)\n",
    "slow_outs = torch.cat(slow_outs)\n",
    "print(torch.all(torch.isclose(fast_outs, slow_outs)))\n",
    "print(fast_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9715e65d-9eee-4823-bdba-71085e4ede03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor([0.4137, 0.5685, 0.4762, 0.5629, 0.5704, 0.5290, 0.6032, 0.6264, 0.6177,\n",
      "        0.5928, 0.3106, 0.6303, 0.6210, 0.5773, 0.5660, 0.5552, 0.5797, 0.5833,\n",
      "        0.6014, 0.5433, 0.5157, 0.4920, 0.5831, 0.5509, 0.6220])\n"
     ]
    }
   ],
   "source": [
    "corpus_similarity = CorpusSimilarity(\n",
    "    encoder=encoder,\n",
    "    corpus_dataloader=corpus_dataloader,\n",
    "    normalize=True,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "fast_outs = []\n",
    "slow_outs = []\n",
    "for explicand, _ in explicand_dataloader:\n",
    "    explicand = explicand.to(device)\n",
    "    fast_out = corpus_similarity.forward(explicand, implementation=\"mean\").detach().cpu()\n",
    "    slow_out = corpus_similarity.forward(explicand, implementation=\"pairwise\").detach().cpu()\n",
    "    fast_outs.append(fast_out)\n",
    "    slow_outs.append(slow_out)\n",
    "fast_outs = torch.cat(fast_outs)\n",
    "slow_outs = torch.cat(slow_outs)\n",
    "print(torch.all(torch.isclose(fast_outs, slow_outs)))\n",
    "print(fast_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5678b38-66b0-43b3-8853-2ee6f427d2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor([ 62.6374, 132.6735, 117.5995, 127.2166, 134.4800, 115.7148, 162.2486,\n",
      "        213.9382, 146.4273, 202.1586,  74.8569, 186.7480, 163.8298, 182.3440,\n",
      "        141.1676, 160.6954, 149.4769, 149.0140, 218.4368, 123.0029, 102.6436,\n",
      "        117.1184, 140.2859, 152.8642, 241.2948])\n"
     ]
    }
   ],
   "source": [
    "corpus_similarity = CorpusSimilarity(\n",
    "    encoder=encoder,\n",
    "    corpus_dataloader=corpus_dataloader,\n",
    "    normalize=False,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "fast_outs = []\n",
    "slow_outs = []\n",
    "for explicand, _ in explicand_dataloader:\n",
    "    explicand = explicand.to(device)\n",
    "    fast_out = corpus_similarity.forward(explicand, implementation=\"mean\").detach().cpu()\n",
    "    slow_out = corpus_similarity.forward(explicand, implementation=\"pairwise\").detach().cpu()\n",
    "    fast_outs.append(fast_out)\n",
    "    slow_outs.append(slow_out)\n",
    "fast_outs = torch.cat(fast_outs)\n",
    "slow_outs = torch.cat(slow_outs)\n",
    "print(torch.all(torch.isclose(fast_outs, slow_outs)))\n",
    "print(fast_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c40118fc-277e-4691-abe0-f64c83ce5bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor([0.1076, 0.2692, 0.2109, 0.3205, 0.3267, 0.2177, 0.3793, 0.3980, 0.3833,\n",
      "        0.3541, 0.0246, 0.4046, 0.3706, 0.3655, 0.3267, 0.3412, 0.3500, 0.3657,\n",
      "        0.4056, 0.2995, 0.2295, 0.2570, 0.3464, 0.3568, 0.4163])\n"
     ]
    }
   ],
   "source": [
    "contrastive_corpus_similarity = ContrastiveCorpusSimilarity(\n",
    "    encoder=encoder,\n",
    "    corpus_dataloader=corpus_dataloader,\n",
    "    foil_dataloader=foil_dataloader,\n",
    "    normalize=True,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "fast_outs = []\n",
    "slow_outs = []\n",
    "for explicand, _ in explicand_dataloader:\n",
    "    explicand = explicand.to(device)\n",
    "    fast_out = contrastive_corpus_similarity.forward(explicand, implementation=\"mean\").detach().cpu()\n",
    "    slow_out = contrastive_corpus_similarity.forward(explicand, implementation=\"pairwise\").detach().cpu()\n",
    "    fast_outs.append(fast_out)\n",
    "    slow_outs.append(slow_out)\n",
    "fast_outs = torch.cat(fast_outs)\n",
    "slow_outs = torch.cat(slow_outs)\n",
    "print(torch.all(torch.isclose(fast_outs, slow_outs)))\n",
    "print(fast_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e29e198e-b147-408f-9cbc-0280a34303c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor([ 22.2385,  72.8735,  61.1973,  80.4654,  85.6751,  57.1075, 111.2328,\n",
      "        147.7859,  99.2391, 132.9886,  14.4126, 130.1294, 107.9386, 125.8127,\n",
      "         90.2288, 108.3405,  99.2070, 102.0712, 158.4294,  75.6810,  53.5171,\n",
      "         69.2056,  92.0039, 107.4272, 173.7889])\n"
     ]
    }
   ],
   "source": [
    "contrastive_corpus_similarity = ContrastiveCorpusSimilarity(\n",
    "    encoder=encoder,\n",
    "    corpus_dataloader=corpus_dataloader,\n",
    "    foil_dataloader=foil_dataloader,\n",
    "    normalize=False,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "fast_outs = []\n",
    "slow_outs = []\n",
    "for explicand, _ in explicand_dataloader:\n",
    "    explicand = explicand.to(device)\n",
    "    fast_out = contrastive_corpus_similarity.forward(explicand, implementation=\"mean\").detach().cpu()\n",
    "    slow_out = contrastive_corpus_similarity.forward(explicand, implementation=\"pairwise\").detach().cpu()\n",
    "    fast_outs.append(fast_out)\n",
    "    slow_outs.append(slow_out)\n",
    "fast_outs = torch.cat(fast_outs)\n",
    "slow_outs = torch.cat(slow_outs)\n",
    "print(torch.all(torch.isclose(fast_outs, slow_outs)))\n",
    "print(fast_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633761e7-ee60-4622-a8ea-3e7f426d3f70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
