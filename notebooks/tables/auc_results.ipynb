{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "292837dc-320c-4975-9aee-50ff7a562adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "from cl_explain.metrics.ablation import compute_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e71332d3-f889-49bc-a192-9ba94fac8850",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_PATH = \"/projects/leelab/cl-explainability/results\"\n",
    "SUPERPIXEL_ATTRIBUTION_METHODS = [\"kernel_shap\"]\n",
    "SEED_LIST = [123, 456, 789, 42, 91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbfd4084-4793-44b7-9371-4dddd543b073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_filename(\n",
    "    different_classes: bool,\n",
    "    comprehensive: bool,\n",
    "    corpus_size: int,\n",
    "    explanation_name: str,\n",
    "    foil_size: int,\n",
    "    explicand_size: int,\n",
    "    attribution_name: str,\n",
    "    superpixel_dim: int,\n",
    "    removal: str,\n",
    "    blur_strength: float,\n",
    "    eval_superpixel_dim: int,\n",
    "    eval_foil_size: int,\n",
    "    take_attribution_abs: bool,\n",
    ") -> str:\n",
    "    \"\"\"Get eval filename.\"\"\"\n",
    "    if different_classes:\n",
    "        eval_filename = \"diff_class\"\n",
    "    else:\n",
    "        eval_filename = \"same_class\"\n",
    "    if comprehensive:\n",
    "        eval_filename += \"_comprehensive\"\n",
    "        \n",
    "    eval_filename += \"_eval_results\"\n",
    "    eval_filename += f\"_explicand_size={explicand_size}\"\n",
    "    if \"corpus\" in explanation_name:\n",
    "        eval_filename += f\"_corpus_size={corpus_size}\"\n",
    "    if \"contrastive\" in explanation_name:\n",
    "        eval_filename += f\"_foil_size={foil_size}\"\n",
    "    if attribution_name in SUPERPIXEL_ATTRIBUTION_METHODS:\n",
    "        eval_filename += f\"_superpixel_dim={superpixel_dim}\"\n",
    "    eval_filename += f\"_removal={removal}\"\n",
    "    if removal == \"blurring\":\n",
    "        eval_filename += f\"_blur_strength={blur_strength:.1f}\"\n",
    "    eval_filename += f\"_eval_superpixel_dim={eval_superpixel_dim}\"\n",
    "    eval_filename += f\"_eval_foil_size={eval_foil_size}\"\n",
    "    if take_attribution_abs:\n",
    "        eval_filename += \"_abs\"\n",
    "    eval_filename += \".pkl\"\n",
    "    return eval_filename\n",
    "\n",
    "\n",
    "def get_mean_curves(outputs, curve_kind) -> Tuple[List[torch.Tensor], int]:\n",
    "    available_curve_kinds = [\"insertion\", \"deletion\"]\n",
    "    assert curve_kind in available_curve_kinds, (\n",
    "        f\"curve_kind={curve_kind} is not one of {available_curve_kinds}!\"\n",
    "    )\n",
    "    target_list = [key for key in outputs.keys()]\n",
    "    eval_name_list = (\n",
    "        outputs[target_list[0]][\"eval_model_names\"]\n",
    "        + outputs[target_list[0]][\"eval_measure_names\"]\n",
    "    )\n",
    "    eval_mean_curve_dict = {}\n",
    "    for j, eval_name in enumerate(eval_name_list):\n",
    "        \n",
    "        curve_list = []\n",
    "        num_features = None\n",
    "\n",
    "        for target, output in outputs.items():\n",
    "            target_curve_list = (\n",
    "                output[f\"model_{curve_kind}_curves\"]\n",
    "                + output[f\"measure_{curve_kind}_curves\"]\n",
    "            )\n",
    "            curve_list.append(target_curve_list[j])\n",
    "            num_features = output[f\"{curve_kind}_num_features\"]\n",
    "        \n",
    "        curves = torch.cat(curve_list)\n",
    "        mean_curve = curves.mean(dim=0).cpu()\n",
    "        eval_mean_curve_dict[eval_name] = mean_curve\n",
    "        \n",
    "    return eval_mean_curve_dict, num_features\n",
    "\n",
    "\n",
    "def get_auc_stats(\n",
    "    dataset: str,\n",
    "    encoder: str,\n",
    "    attribution: str,\n",
    "    eval_name: str,\n",
    "    normalize_similarity: bool,\n",
    "    different_classes: bool,\n",
    "    comprehensive: bool = False,\n",
    "    explicand_size: int = 25,\n",
    "    removal: str = \"blurring\",\n",
    "    blur_strength: float = 5.0,\n",
    "    superpixel_dim: int = 1,\n",
    "    eval_superpixel_dim: int = 1,\n",
    "    foil_size: int = 1500,\n",
    "    corpus_size: int = 100,\n",
    "    eval_foil_size: int = 1500,\n",
    "    take_attribution_abs: bool = False,\n",
    ") -> Dict[str, Dict[str, List]]:\n",
    "    if attribution == \"random_baseline\":\n",
    "        explanation_list = [\"self_weighted\"]\n",
    "    else:\n",
    "        explanation_list = [  # Make sure to order this way.\n",
    "            \"self_weighted\",\n",
    "            \"contrastive_self_weighted\",\n",
    "            \"corpus\",\n",
    "            \"contrastive_corpus\",\n",
    "        ]\n",
    "        \n",
    "    insertion_mean_list = []\n",
    "    insertion_ci_list = []\n",
    "    deletion_mean_list = []\n",
    "    deletion_ci_list = []\n",
    "\n",
    "    for explanation in explanation_list:\n",
    "        insertion_list = []\n",
    "        deletion_list = []\n",
    "        for seed in SEED_LIST:            \n",
    "            eval_filename = get_eval_filename(\n",
    "                different_classes=different_classes,\n",
    "                comprehensive=comprehensive,\n",
    "                corpus_size=corpus_size,\n",
    "                explanation_name=explanation,\n",
    "                foil_size=foil_size,\n",
    "                explicand_size=explicand_size,\n",
    "                attribution_name=attribution,\n",
    "                superpixel_dim=superpixel_dim,\n",
    "                removal=removal,\n",
    "                blur_strength=blur_strength,\n",
    "                eval_superpixel_dim=eval_superpixel_dim,\n",
    "                eval_foil_size=eval_foil_size,\n",
    "                take_attribution_abs=take_attribution_abs,\n",
    "            )\n",
    "\n",
    "            if normalize_similarity:\n",
    "                method_name = \"normalized\"\n",
    "            else:\n",
    "                method_name = \"unnormalized\"\n",
    "            method_name += f\"_{explanation}_{attribution}\"\n",
    "            with open(\n",
    "                os.path.join(\n",
    "                    RESULT_PATH,\n",
    "                    dataset,\n",
    "                    encoder,\n",
    "                    method_name,\n",
    "                    f\"{seed}\",\n",
    "                    eval_filename,\n",
    "                ),\n",
    "                \"rb\",\n",
    "            ) as handle:\n",
    "                outputs = pickle.load(handle)\n",
    "            insertion_curve_dict, insertion_num_features = get_mean_curves(\n",
    "                outputs, \"insertion\"\n",
    "            )\n",
    "            deletion_curve_dict, deletion_num_features = get_mean_curves(\n",
    "                outputs, \"deletion\"\n",
    "            )\n",
    "            insertion_list.append(\n",
    "                compute_auc(\n",
    "                    curve=insertion_curve_dict[eval_name],\n",
    "                    num_features=insertion_num_features,\n",
    "                )\n",
    "            )\n",
    "            deletion_list.append(\n",
    "                compute_auc(\n",
    "                    curve=deletion_curve_dict[eval_name],\n",
    "                    num_features=deletion_num_features,\n",
    "                )\n",
    "            )\n",
    "        insertion_mean_list.append(np.mean(insertion_list))\n",
    "        insertion_ci_list.append(1.96 * np.std(insertion_list) / np.sqrt(len(SEED_LIST)))\n",
    "        deletion_mean_list.append(np.mean(deletion_list))\n",
    "        deletion_ci_list.append(1.96 * np.std(deletion_list) / np.sqrt(len(SEED_LIST)))\n",
    "    return {\n",
    "        \"insertion\": {\"mean\": insertion_mean_list, \"ci\": insertion_ci_list},\n",
    "        \"deletion\": {\"mean\": deletion_mean_list, \"ci\": deletion_ci_list},\n",
    "    }\n",
    "\n",
    "\n",
    "def get_formatted_aucs(\n",
    "    insertion_direction: str,\n",
    "    deletion_direction: str,\n",
    "    bold_best: bool = True,\n",
    "    **kwargs,\n",
    "):\n",
    "    auc_stats = get_auc_stats(**kwargs)\n",
    "    \n",
    "    insertion_mean_list = auc_stats[\"insertion\"][\"mean\"]\n",
    "    insertion_ci_list = auc_stats[\"insertion\"][\"ci\"]\n",
    "    if insertion_direction == \"max\":\n",
    "        insertion_best_idx = np.argmax(insertion_mean_list)\n",
    "    elif insertion_direction == \"min\":\n",
    "        insertion_best_idx = np.argmin(insertion_mean_list)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"insertion_direction={insertion_direction} should be max or min!\"\n",
    "        )\n",
    "        \n",
    "    deletion_mean_list = auc_stats[\"deletion\"][\"mean\"]\n",
    "    deletion_ci_list = auc_stats[\"deletion\"][\"ci\"]\n",
    "    if deletion_direction == \"max\":\n",
    "        deletion_best_idx = np.argmax(deletion_mean_list)\n",
    "    elif deletion_direction == \"min\":\n",
    "        deletion_best_idx = np.argmin(deletion_mean_list)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"deietion_direction={deietion_direction} should be max or min!\"\n",
    "        )\n",
    "    \n",
    "    text_list = []\n",
    "    for i in range(len(insertion_mean_list)):\n",
    "        insertion_mean = insertion_mean_list[i]\n",
    "        insertion_ci = insertion_ci_list[i]\n",
    "        if insertion_mean < 0.01:\n",
    "            insertion_text = (\n",
    "                \"{:.2e}\".format(insertion_mean)\n",
    "                + \" $\\pm$ \"\n",
    "                + \"{:.2e}\".format(insertion_ci)\n",
    "            )\n",
    "        else:\n",
    "            insertion_text = f\"{insertion_mean:.3f} $\\pm$ {insertion_ci:.3f}\"\n",
    "        if i == insertion_best_idx and bold_best:\n",
    "            insertion_text = \"\\\\textbf{\" + insertion_text + \"}\"\n",
    "            \n",
    "        deletion_mean = deletion_mean_list[i]\n",
    "        deletion_ci = deletion_ci_list[i]\n",
    "        if deletion_mean < 0.01:\n",
    "            deletion_text = (\n",
    "                \"{:.2e}\".format(deletion_mean)\n",
    "                + \" $\\pm$ \"\n",
    "                + \"{:.2e}\".format(deletion_ci)\n",
    "            )\n",
    "        else:\n",
    "            deletion_text = f\"{deletion_mean:.3f} $\\pm$ {deletion_ci:.3f}\"\n",
    "        if i == deletion_best_idx and bold_best:\n",
    "            deletion_text = \"\\\\textbf{\" + deletion_text + \"}\"\n",
    "            \n",
    "        text = insertion_text + \" & \" + deletion_text\n",
    "        text_list.append(text)\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13745d86-38e1-44b8-a15e-090a4107192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_aucs(\n",
    "    eval_name: str,\n",
    "    normalize_similarity: bool,\n",
    "    different_classes: bool,\n",
    "    insertion_direction: str = \"max\",\n",
    "    deletion_direction: str = \"min\",\n",
    "):\n",
    "    attribution_list = [\"int_grad\", \"gradient_shap\", \"rise\"]\n",
    "    dataset_encoder_combos = [\n",
    "        (\"imagenet\", \"simclr_x1\"),\n",
    "        (\"cifar\", \"simsiam_18\"),\n",
    "        (\"mura\", \"classifier_18\"),\n",
    "    ]\n",
    "    for attribution in attribution_list:\n",
    "        print(attribution)\n",
    "        print(\"-\" * len(attribution))\n",
    "        label_free_text = \"Label-Free\"\n",
    "        contrastive_label_free_text = \"Contrastive Label-Free\"\n",
    "        corpus_text = \"Corpus\"\n",
    "        cocoa_text = \"COCOA\"\n",
    "        for dataset_encoder in dataset_encoder_combos:\n",
    "            text_list = get_formatted_aucs(\n",
    "                insertion_direction=insertion_direction,\n",
    "                deletion_direction=deletion_direction,\n",
    "                dataset=dataset_encoder[0],\n",
    "                encoder=dataset_encoder[1],\n",
    "                attribution=attribution,\n",
    "                eval_name=eval_name,\n",
    "                normalize_similarity=normalize_similarity,\n",
    "                different_classes=different_classes,\n",
    "            )\n",
    "            label_free_text += f\" & {text_list[0]}\"\n",
    "            contrastive_label_free_text += f\" & {text_list[1]}\"\n",
    "            corpus_text += f\" & {text_list[2]}\"\n",
    "            cocoa_text += f\" & {text_list[3]}\"\n",
    "        print(\"& \" + label_free_text + \" \\\\\\\\\")\n",
    "        print(\"& \" + contrastive_label_free_text + \" \\\\\\\\\")\n",
    "        print(\"& \" + corpus_text + \" \\\\\\\\\")\n",
    "        print(\"& \" + cocoa_text + \" \\\\\\\\\")\n",
    "        print(\"\")\n",
    "\n",
    "    print(\"random\")\n",
    "    print(\"------\")\n",
    "    random_text = \"None\"\n",
    "    for dataset_encoder in dataset_encoder_combos:\n",
    "        text_list = get_formatted_aucs(\n",
    "            insertion_direction=insertion_direction,\n",
    "            deletion_direction=deletion_direction,\n",
    "            bold_best=False,\n",
    "            dataset=dataset_encoder[0],\n",
    "            encoder=dataset_encoder[1],\n",
    "            attribution=\"random_baseline\",\n",
    "            eval_name=eval_name,\n",
    "            normalize_similarity=normalize_similarity,\n",
    "            different_classes=different_classes,\n",
    "        )\n",
    "        random_text += f\" & {text_list[0]}\"\n",
    "    print(\"& \" + random_text + \" \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bd35bd-28ce-4547-b576-cc4edf54d3e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Corpus Majority Probability (Cosine Similarity & Same Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74daec49-1e13-44be-8b72-6bf225b122aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int_grad\n",
      "--------\n",
      "& Label-Free & 0.362 $\\pm$ 0.005 & 0.136 $\\pm$ 0.004 & \\textbf{0.403 $\\pm$ 0.010} & 0.249 $\\pm$ 0.007 & 0.631 $\\pm$ 0.040 & 0.513 $\\pm$ 0.027 \\\\\n",
      "& Contrastive Label-Free & 0.377 $\\pm$ 0.005 & 0.125 $\\pm$ 0.003 & 0.401 $\\pm$ 0.011 & 0.243 $\\pm$ 0.007 & 0.690 $\\pm$ 0.019 & 0.453 $\\pm$ 0.025 \\\\\n",
      "& Corpus & 0.377 $\\pm$ 0.005 & 0.147 $\\pm$ 0.002 & 0.355 $\\pm$ 0.014 & 0.249 $\\pm$ 0.010 & 0.653 $\\pm$ 0.014 & 0.500 $\\pm$ 0.039 \\\\\n",
      "& COCOA & \\textbf{0.422 $\\pm$ 0.006} & \\textbf{0.119 $\\pm$ 0.003} & 0.386 $\\pm$ 0.012 & \\textbf{0.230 $\\pm$ 0.011} & \\textbf{0.807 $\\pm$ 0.013} & \\textbf{0.330 $\\pm$ 0.030} \\\\\n",
      "\n",
      "gradient_shap\n",
      "-------------\n",
      "& Label-Free & 0.409 $\\pm$ 0.004 & 0.131 $\\pm$ 0.001 & 0.500 $\\pm$ 0.008 & 0.244 $\\pm$ 0.013 & 0.691 $\\pm$ 0.038 & 0.523 $\\pm$ 0.033 \\\\\n",
      "& Contrastive Label-Free & 0.411 $\\pm$ 0.003 & 0.127 $\\pm$ 0.002 & 0.500 $\\pm$ 0.009 & 0.238 $\\pm$ 0.012 & 0.697 $\\pm$ 0.037 & 0.510 $\\pm$ 0.018 \\\\\n",
      "& Corpus & 0.421 $\\pm$ 0.006 & 0.136 $\\pm$ 0.001 & 0.478 $\\pm$ 0.008 & 0.242 $\\pm$ 0.009 & 0.729 $\\pm$ 0.024 & 0.494 $\\pm$ 0.037 \\\\\n",
      "& COCOA & \\textbf{0.445 $\\pm$ 0.003} & \\textbf{0.123 $\\pm$ 0.002} & \\textbf{0.508 $\\pm$ 0.007} & \\textbf{0.211 $\\pm$ 0.008} & \\textbf{0.788 $\\pm$ 0.030} & \\textbf{0.419 $\\pm$ 0.013} \\\\\n",
      "\n",
      "rise\n",
      "----\n",
      "& Label-Free & 0.396 $\\pm$ 0.005 & 0.160 $\\pm$ 0.005 & 0.630 $\\pm$ 0.005 & 0.283 $\\pm$ 0.004 & 0.704 $\\pm$ 0.022 & 0.600 $\\pm$ 0.012 \\\\\n",
      "& Contrastive Label-Free & 0.424 $\\pm$ 0.008 & 0.141 $\\pm$ 0.005 & 0.632 $\\pm$ 0.008 & 0.279 $\\pm$ 0.004 & 0.730 $\\pm$ 0.019 & 0.534 $\\pm$ 0.015 \\\\\n",
      "& Corpus & 0.394 $\\pm$ 0.010 & 0.166 $\\pm$ 0.003 & 0.588 $\\pm$ 0.005 & 0.314 $\\pm$ 0.006 & 0.701 $\\pm$ 0.019 & 0.617 $\\pm$ 0.026 \\\\\n",
      "& COCOA & \\textbf{0.456 $\\pm$ 0.009} & \\textbf{0.126 $\\pm$ 0.001} & \\textbf{0.663 $\\pm$ 0.006} & \\textbf{0.256 $\\pm$ 0.006} & \\textbf{0.840 $\\pm$ 0.009} & \\textbf{0.415 $\\pm$ 0.025} \\\\\n",
      "\n",
      "random\n",
      "------\n",
      "& None & 0.269 $\\pm$ 0.003 & 0.268 $\\pm$ 0.002 & 0.329 $\\pm$ 0.013 & 0.329 $\\pm$ 0.010 & 0.624 $\\pm$ 0.018 & 0.629 $\\pm$ 0.018 \\\\\n"
     ]
    }
   ],
   "source": [
    "print_aucs(eval_name=\"corpus_majority_prob\", normalize_similarity=True, different_classes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6e4dba-34c0-44e9-a980-552d6146d8c3",
   "metadata": {},
   "source": [
    "## Corpus Majority Probability (Cosine Similarity & Different Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "084d4916-7070-47e9-8697-50cd0104dda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int_grad\n",
      "--------\n",
      "& Label-Free & 3.53e-04 $\\pm$ 1.06e-04 & 4.44e-04 $\\pm$ 1.01e-04 & 0.061 $\\pm$ 0.004 & 0.079 $\\pm$ 0.004 & 0.394 $\\pm$ 0.028 & 0.481 $\\pm$ 0.031 \\\\\n",
      "& Contrastive Label-Free & 3.36e-04 $\\pm$ 1.13e-04 & 4.44e-04 $\\pm$ 1.00e-04 & 0.062 $\\pm$ 0.004 & 0.082 $\\pm$ 0.004 & 0.354 $\\pm$ 0.022 & 0.518 $\\pm$ 0.027 \\\\\n",
      "& Corpus & 1.09e-03 $\\pm$ 2.85e-04 & 2.26e-04 $\\pm$ 5.31e-05 & 0.094 $\\pm$ 0.003 & 0.066 $\\pm$ 0.003 & 0.609 $\\pm$ 0.017 & 0.262 $\\pm$ 0.029 \\\\\n",
      "& COCOA & \\textbf{1.69e-03 $\\pm$ 5.07e-04} & \\textbf{1.55e-04 $\\pm$ 2.21e-05} & \\textbf{0.099 $\\pm$ 0.004} & \\textbf{0.059 $\\pm$ 0.005} & \\textbf{0.647 $\\pm$ 0.017} & \\textbf{0.213 $\\pm$ 0.030} \\\\\n",
      "\n",
      "gradient_shap\n",
      "-------------\n",
      "& Label-Free & 2.05e-04 $\\pm$ 5.96e-05 & 5.55e-04 $\\pm$ 1.11e-04 & 0.054 $\\pm$ 0.004 & 0.080 $\\pm$ 0.004 & 0.362 $\\pm$ 0.031 & 0.469 $\\pm$ 0.021 \\\\\n",
      "& Contrastive Label-Free & 2.02e-04 $\\pm$ 5.06e-05 & 5.10e-04 $\\pm$ 9.65e-05 & 0.053 $\\pm$ 0.002 & 0.080 $\\pm$ 0.004 & 0.361 $\\pm$ 0.022 & 0.477 $\\pm$ 0.018 \\\\\n",
      "& Corpus & 8.03e-04 $\\pm$ 1.64e-04 & 2.65e-04 $\\pm$ 5.44e-05 & 0.106 $\\pm$ 0.006 & 0.055 $\\pm$ 0.003 & 0.549 $\\pm$ 0.020 & 0.325 $\\pm$ 0.019 \\\\\n",
      "& COCOA & \\textbf{1.56e-03 $\\pm$ 4.32e-04} & \\textbf{1.67e-04 $\\pm$ 5.66e-05} & \\textbf{0.122 $\\pm$ 0.008} & \\textbf{0.045 $\\pm$ 0.003} & \\textbf{0.592 $\\pm$ 0.025} & \\textbf{0.236 $\\pm$ 0.012} \\\\\n",
      "\n",
      "rise\n",
      "----\n",
      "& Label-Free & 3.70e-04 $\\pm$ 7.34e-05 & 5.37e-04 $\\pm$ 1.23e-04 & 0.039 $\\pm$ 0.003 & 0.080 $\\pm$ 0.005 & 0.330 $\\pm$ 0.016 & 0.433 $\\pm$ 0.030 \\\\\n",
      "& Contrastive Label-Free & 3.32e-04 $\\pm$ 1.14e-04 & 5.84e-04 $\\pm$ 8.24e-05 & 0.040 $\\pm$ 0.003 & 0.081 $\\pm$ 0.005 & 0.307 $\\pm$ 0.018 & 0.472 $\\pm$ 0.027 \\\\\n",
      "& Corpus & 4.79e-04 $\\pm$ 9.68e-05 & 3.87e-04 $\\pm$ 8.41e-05 & 0.086 $\\pm$ 0.005 & 0.043 $\\pm$ 0.003 & 0.497 $\\pm$ 0.031 & 0.269 $\\pm$ 0.020 \\\\\n",
      "& COCOA & \\textbf{9.51e-04 $\\pm$ 2.58e-04} & \\textbf{3.60e-04 $\\pm$ 1.40e-04} & \\textbf{0.107 $\\pm$ 0.007} & \\textbf{0.031 $\\pm$ 0.002} & \\textbf{0.590 $\\pm$ 0.027} & \\textbf{0.181 $\\pm$ 0.014} \\\\\n",
      "\n",
      "random\n",
      "------\n",
      "& None & 4.87e-04 $\\pm$ 9.50e-05 & 5.03e-04 $\\pm$ 9.73e-05 & 0.070 $\\pm$ 0.003 & 0.070 $\\pm$ 0.004 & 0.406 $\\pm$ 0.013 & 0.407 $\\pm$ 0.016 \\\\\n"
     ]
    }
   ],
   "source": [
    "print_aucs(eval_name=\"corpus_majority_prob\", normalize_similarity=True, different_classes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510e0c17-0124-4c38-beaf-384d43800c4e",
   "metadata": {},
   "source": [
    "## Explicand Probability (Cosine Similarity & Same Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ac63a00-d861-4935-8afe-3466b79f7581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int_grad\n",
      "--------\n",
      "& Label-Free & 0.399 $\\pm$ 0.007 & 0.143 $\\pm$ 0.004 & \\textbf{0.412 $\\pm$ 0.008} & 0.255 $\\pm$ 0.008 & 0.642 $\\pm$ 0.043 & 0.491 $\\pm$ 0.015 \\\\\n",
      "& Contrastive Label-Free & 0.414 $\\pm$ 0.006 & \\textbf{0.131 $\\pm$ 0.004} & 0.411 $\\pm$ 0.011 & 0.250 $\\pm$ 0.008 & \\textbf{0.717 $\\pm$ 0.023} & \\textbf{0.416 $\\pm$ 0.018} \\\\\n",
      "& Corpus & 0.386 $\\pm$ 0.006 & 0.164 $\\pm$ 0.005 & 0.358 $\\pm$ 0.013 & 0.258 $\\pm$ 0.011 & 0.559 $\\pm$ 0.029 & 0.595 $\\pm$ 0.028 \\\\\n",
      "& COCOA & \\textbf{0.435 $\\pm$ 0.006} & 0.132 $\\pm$ 0.005 & 0.387 $\\pm$ 0.012 & \\textbf{0.241 $\\pm$ 0.011} & 0.713 $\\pm$ 0.032 & 0.425 $\\pm$ 0.025 \\\\\n",
      "\n",
      "gradient_shap\n",
      "-------------\n",
      "& Label-Free & 0.455 $\\pm$ 0.004 & 0.138 $\\pm$ 0.002 & 0.512 $\\pm$ 0.008 & 0.249 $\\pm$ 0.012 & \\textbf{0.747 $\\pm$ 0.029} & 0.478 $\\pm$ 0.021 \\\\\n",
      "& Contrastive Label-Free & 0.458 $\\pm$ 0.004 & \\textbf{0.135 $\\pm$ 0.003} & \\textbf{0.512 $\\pm$ 0.010} & 0.243 $\\pm$ 0.011 & 0.742 $\\pm$ 0.035 & \\textbf{0.460 $\\pm$ 0.009} \\\\\n",
      "& Corpus & 0.444 $\\pm$ 0.006 & 0.150 $\\pm$ 0.003 & 0.477 $\\pm$ 0.008 & 0.252 $\\pm$ 0.010 & 0.684 $\\pm$ 0.030 & 0.539 $\\pm$ 0.034 \\\\\n",
      "& COCOA & \\textbf{0.470 $\\pm$ 0.003} & 0.135 $\\pm$ 0.003 & 0.505 $\\pm$ 0.008 & \\textbf{0.223 $\\pm$ 0.010} & 0.709 $\\pm$ 0.039 & 0.501 $\\pm$ 0.032 \\\\\n",
      "\n",
      "rise\n",
      "----\n",
      "& Label-Free & 0.434 $\\pm$ 0.006 & 0.180 $\\pm$ 0.005 & 0.651 $\\pm$ 0.004 & 0.287 $\\pm$ 0.005 & 0.785 $\\pm$ 0.023 & 0.636 $\\pm$ 0.027 \\\\\n",
      "& Contrastive Label-Free & 0.463 $\\pm$ 0.006 & 0.160 $\\pm$ 0.003 & 0.654 $\\pm$ 0.007 & 0.282 $\\pm$ 0.008 & \\textbf{0.826 $\\pm$ 0.014} & \\textbf{0.554 $\\pm$ 0.032} \\\\\n",
      "& Corpus & 0.423 $\\pm$ 0.008 & 0.190 $\\pm$ 0.003 & 0.595 $\\pm$ 0.007 & 0.328 $\\pm$ 0.008 & 0.703 $\\pm$ 0.021 & 0.722 $\\pm$ 0.030 \\\\\n",
      "& COCOA & \\textbf{0.486 $\\pm$ 0.009} & \\textbf{0.147 $\\pm$ 0.001} & \\textbf{0.663 $\\pm$ 0.009} & \\textbf{0.272 $\\pm$ 0.006} & 0.810 $\\pm$ 0.030 & 0.554 $\\pm$ 0.024 \\\\\n",
      "\n",
      "random\n",
      "------\n",
      "& None & 0.291 $\\pm$ 0.003 & 0.291 $\\pm$ 0.003 & 0.338 $\\pm$ 0.012 & 0.336 $\\pm$ 0.010 & 0.644 $\\pm$ 0.021 & 0.649 $\\pm$ 0.022 \\\\\n"
     ]
    }
   ],
   "source": [
    "print_aucs(eval_name=\"explicand_pred_prob\", normalize_similarity=True, different_classes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7225a93f-e421-4848-a823-62311c58e2ca",
   "metadata": {},
   "source": [
    "## Explicand Representation Shift (Cosine Similarity & Same Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5af50e57-8700-4c56-b25c-71f71f128f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int_grad\n",
      "--------\n",
      "& Label-Free & 8.819 $\\pm$ 0.079 & 11.626 $\\pm$ 0.097 & \\textbf{0.125 $\\pm$ 0.001} & 0.136 $\\pm$ 0.001 & 10.752 $\\pm$ 0.541 & 11.563 $\\pm$ 0.667 \\\\\n",
      "& Contrastive Label-Free & \\textbf{8.719 $\\pm$ 0.084} & \\textbf{11.755 $\\pm$ 0.097} & 0.125 $\\pm$ 0.001 & \\textbf{0.136 $\\pm$ 0.001} & \\textbf{10.025 $\\pm$ 0.387} & \\textbf{12.866 $\\pm$ 0.442} \\\\\n",
      "& Corpus & 9.659 $\\pm$ 0.080 & 10.904 $\\pm$ 0.098 & 0.131 $\\pm$ 0.001 & 0.134 $\\pm$ 0.001 & 12.224 $\\pm$ 0.543 & 10.354 $\\pm$ 0.721 \\\\\n",
      "& COCOA & 9.234 $\\pm$ 0.083 & 11.355 $\\pm$ 0.096 & 0.130 $\\pm$ 0.001 & 0.134 $\\pm$ 0.001 & 10.920 $\\pm$ 0.561 & 12.628 $\\pm$ 0.548 \\\\\n",
      "\n",
      "gradient_shap\n",
      "-------------\n",
      "& Label-Free & 7.936 $\\pm$ 0.054 & 11.826 $\\pm$ 0.107 & 0.120 $\\pm$ 0.001 & \\textbf{0.139 $\\pm$ 0.001} & \\textbf{7.589 $\\pm$ 0.404} & \\textbf{12.184 $\\pm$ 0.904} \\\\\n",
      "& Contrastive Label-Free & \\textbf{7.912 $\\pm$ 0.051} & \\textbf{11.872 $\\pm$ 0.111} & \\textbf{0.120 $\\pm$ 0.001} & 0.139 $\\pm$ 0.001 & 8.092 $\\pm$ 0.440 & 11.789 $\\pm$ 0.917 \\\\\n",
      "& Corpus & 8.574 $\\pm$ 0.065 & 11.322 $\\pm$ 0.108 & 0.126 $\\pm$ 0.001 & 0.135 $\\pm$ 0.001 & 8.615 $\\pm$ 0.394 & 11.249 $\\pm$ 0.807 \\\\\n",
      "& COCOA & 8.381 $\\pm$ 0.061 & 11.527 $\\pm$ 0.113 & 0.125 $\\pm$ 0.001 & 0.135 $\\pm$ 0.001 & 8.856 $\\pm$ 0.459 & 11.179 $\\pm$ 0.883 \\\\\n",
      "\n",
      "rise\n",
      "----\n",
      "& Label-Free & 7.671 $\\pm$ 0.068 & 11.021 $\\pm$ 0.085 & 0.086 $\\pm$ 0.001 & 0.144 $\\pm$ 0.001 & 4.312 $\\pm$ 0.152 & 7.937 $\\pm$ 0.636 \\\\\n",
      "& Contrastive Label-Free & \\textbf{7.216 $\\pm$ 0.067} & \\textbf{11.172 $\\pm$ 0.079} & \\textbf{0.085 $\\pm$ 0.001} & \\textbf{0.145 $\\pm$ 0.001} & \\textbf{3.989 $\\pm$ 0.192} & \\textbf{9.496 $\\pm$ 0.745} \\\\\n",
      "& Corpus & 8.289 $\\pm$ 0.093 & 10.612 $\\pm$ 0.079 & 0.101 $\\pm$ 0.001 & 0.133 $\\pm$ 0.001 & 6.983 $\\pm$ 0.697 & 5.493 $\\pm$ 0.312 \\\\\n",
      "& COCOA & 7.426 $\\pm$ 0.069 & 10.912 $\\pm$ 0.099 & 0.093 $\\pm$ 0.001 & 0.137 $\\pm$ 0.001 & 5.330 $\\pm$ 0.218 & 8.316 $\\pm$ 0.549 \\\\\n",
      "\n",
      "random\n",
      "------\n",
      "& None & 9.893 $\\pm$ 0.081 & 9.894 $\\pm$ 0.085 & 0.133 $\\pm$ 0.001 & 0.133 $\\pm$ 0.001 & 8.425 $\\pm$ 0.465 & 8.421 $\\pm$ 0.487 \\\\\n"
     ]
    }
   ],
   "source": [
    "print_aucs(\n",
    "    eval_name=\"explicand_rep_shift\",\n",
    "    normalize_similarity=True,\n",
    "    different_classes=False,\n",
    "    insertion_direction=\"min\",\n",
    "    deletion_direction=\"max\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77142d17-ff82-4c9f-8daa-324a8942742d",
   "metadata": {},
   "source": [
    "## Explicand Representation Shift (Cosine Similarity & Different Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cd712d9-0728-4870-b65b-479b2d9d0b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int_grad\n",
      "--------\n",
      "& Label-Free & 8.764 $\\pm$ 0.141 & 11.556 $\\pm$ 0.207 & \\textbf{0.125 $\\pm$ 0.001} & 0.136 $\\pm$ 0.000 & 11.025 $\\pm$ 0.366 & 11.727 $\\pm$ 0.781 \\\\\n",
      "& Contrastive Label-Free & \\textbf{8.664 $\\pm$ 0.137} & \\textbf{11.676 $\\pm$ 0.209} & 0.125 $\\pm$ 0.001 & \\textbf{0.136 $\\pm$ 0.000} & \\textbf{10.096 $\\pm$ 0.352} & \\textbf{13.011 $\\pm$ 0.607} \\\\\n",
      "& Corpus & 10.956 $\\pm$ 0.214 & 9.584 $\\pm$ 0.131 & 0.134 $\\pm$ 0.000 & 0.132 $\\pm$ 0.000 & 13.479 $\\pm$ 0.579 & 9.988 $\\pm$ 0.378 \\\\\n",
      "& COCOA & 10.048 $\\pm$ 0.179 & 10.573 $\\pm$ 0.174 & 0.133 $\\pm$ 0.000 & 0.132 $\\pm$ 0.000 & 12.391 $\\pm$ 0.650 & 10.988 $\\pm$ 0.475 \\\\\n",
      "\n",
      "gradient_shap\n",
      "-------------\n",
      "& Label-Free & 7.857 $\\pm$ 0.102 & 11.754 $\\pm$ 0.194 & 0.121 $\\pm$ 0.001 & \\textbf{0.140 $\\pm$ 0.001} & \\textbf{7.650 $\\pm$ 0.346} & \\textbf{12.353 $\\pm$ 0.667} \\\\\n",
      "& Contrastive Label-Free & \\textbf{7.828 $\\pm$ 0.099} & \\textbf{11.802 $\\pm$ 0.195} & \\textbf{0.121 $\\pm$ 0.001} & 0.140 $\\pm$ 0.001 & 8.057 $\\pm$ 0.475 & 12.226 $\\pm$ 0.780 \\\\\n",
      "& Corpus & 10.250 $\\pm$ 0.177 & 9.800 $\\pm$ 0.163 & 0.132 $\\pm$ 0.000 & 0.132 $\\pm$ 0.001 & 10.727 $\\pm$ 0.582 & 9.600 $\\pm$ 0.449 \\\\\n",
      "& COCOA & 9.926 $\\pm$ 0.158 & 10.170 $\\pm$ 0.184 & 0.133 $\\pm$ 0.000 & 0.131 $\\pm$ 0.000 & 11.224 $\\pm$ 0.627 & 9.052 $\\pm$ 0.372 \\\\\n",
      "\n",
      "rise\n",
      "----\n",
      "& Label-Free & 7.608 $\\pm$ 0.086 & 10.924 $\\pm$ 0.196 & 0.086 $\\pm$ 0.001 & 0.145 $\\pm$ 0.001 & 4.448 $\\pm$ 0.332 & 7.751 $\\pm$ 0.551 \\\\\n",
      "& Contrastive Label-Free & \\textbf{7.139 $\\pm$ 0.085} & \\textbf{11.094 $\\pm$ 0.177} & \\textbf{0.085 $\\pm$ 0.001} & \\textbf{0.145 $\\pm$ 0.001} & \\textbf{4.009 $\\pm$ 0.306} & \\textbf{9.575 $\\pm$ 0.617} \\\\\n",
      "& Corpus & 9.967 $\\pm$ 0.208 & 9.088 $\\pm$ 0.060 & 0.120 $\\pm$ 0.001 & 0.116 $\\pm$ 0.001 & 8.276 $\\pm$ 0.775 & 4.498 $\\pm$ 0.228 \\\\\n",
      "& COCOA & 9.090 $\\pm$ 0.165 & 9.510 $\\pm$ 0.109 & 0.123 $\\pm$ 0.002 & 0.111 $\\pm$ 0.001 & 8.002 $\\pm$ 0.641 & 5.813 $\\pm$ 0.493 \\\\\n",
      "\n",
      "random\n",
      "------\n",
      "& None & 9.805 $\\pm$ 0.161 & 9.810 $\\pm$ 0.158 & 0.133 $\\pm$ 0.000 & 0.133 $\\pm$ 0.000 & 8.823 $\\pm$ 0.433 & 8.808 $\\pm$ 0.431 \\\\\n"
     ]
    }
   ],
   "source": [
    "print_aucs(\n",
    "    eval_name=\"explicand_rep_shift\",\n",
    "    normalize_similarity=True,\n",
    "    different_classes=True,\n",
    "    insertion_direction=\"min\",\n",
    "    deletion_direction=\"max\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b382bc-f2a7-4fcd-b0a2-5d4648c2e7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
